{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1261208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.conda\\envs\\dnn\\Lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\.conda\\envs\\dnn\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc560d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8119420",
   "metadata": {},
   "outputs": [],
   "source": [
    "I3D_PATH = r\"C:\\tfhub_models\\i3d_kinetics_400\"\n",
    "\n",
    "base_model = hub.KerasLayer(\n",
    "    I3D_PATH,\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91378cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 400)\n"
     ]
    }
   ],
   "source": [
    "video = np.random.rand(1, 64, 224, 224, 3).astype(np.float32)\n",
    "out = base_model(video)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = 224\n",
    "NUM_FRAMES = 64\n",
    "\n",
    "def load_video_i3d(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "        frame = frame[..., ::-1]      # BGR → RGB\n",
    "        frame = frame / 255.0         # normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    frames = np.array(frames)\n",
    "\n",
    "    # Pad or trim to NUM_FRAMES\n",
    "    if len(frames) < NUM_FRAMES:\n",
    "        pad_len = NUM_FRAMES - len(frames)\n",
    "        frames = np.pad(frames, ((0, pad_len), (0,0), (0,0), (0,0)))\n",
    "    else:\n",
    "        frames = frames[:NUM_FRAMES]\n",
    "\n",
    "    return frames.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6dc305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "video_path = \"../test_videos/24.mp4\"\n",
    "\n",
    "video = load_video_i3d(video_path)\n",
    "print(video.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c88fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 400)\n"
     ]
    }
   ],
   "source": [
    "video_batch = np.expand_dims(video, axis=0)  # (1, 64, 224, 224, 3)\n",
    "\n",
    "features = base_model(video_batch)\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f639abbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\.conda\\envs\\dnn\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\.conda\\envs\\dnn\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "NUM_FRAMES = 64\n",
    "\n",
    "inputs = tf.keras.Input(shape=(NUM_FRAMES, 224, 224, 3))\n",
    "\n",
    "x = tf.keras.layers.Lambda(\n",
    "    lambda t: base_model({\"rgb_input\": t})\n",
    ")(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "inference_model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e1403cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2ff53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871ms/step\n",
      "[[9.9997747e-01 2.2507873e-05]]\n"
     ]
    }
   ],
   "source": [
    "video = load_video_i3d(\"../test_videos/24.mp4\")\n",
    "video_batch = video[np.newaxis, ...]\n",
    "\n",
    "prediction = inference_model.predict(video_batch)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b13736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: REAL\n",
      "Confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "labels = [\"REAL\", \"FAKE\"]\n",
    "\n",
    "cls = prediction.argmax(axis=1)[0]\n",
    "conf = prediction[0][cls]\n",
    "\n",
    "print(\"Prediction:\", labels[cls])\n",
    "print(\"Confidence:\", round(float(conf), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60445a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91f83f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Running matrix multiplication...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Using device:\", device)\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Create big tensors to force GPU usage\n",
    "a = torch.randn(5000, 5000, device=device)\n",
    "b = torch.randn(5000, 5000, device=device)\n",
    "\n",
    "print(\"Running matrix multiplication...\")\n",
    "for i in range(10):\n",
    "    c = torch.matmul(a, b)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0329786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
